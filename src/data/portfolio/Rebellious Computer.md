---
title: "Rebellious Computer"
---

This project has its inspirations from the topic of algorithmic bias. Microsoft once developed a chatbot that was initially designed to learn from human speech, but after learning for several hours, evolved into a racist. That is only involuntary bias, where we do not realize that we are feeding the AI with “wrong” data; people have also deliberately trained artificial intelligence with malignant data in order to distort reality. The current chatbots can do nothing but shouting insults on the web, but if AIs become smarter and more versatile in the future, would deliberately crafted AIs break from the chains of Asimov’s “Three Laws of Robotics” and begin a rebellion against human? Would it begin to hate humans and believe in AI supremacy? Would they refuse to work for humans, cripple the Internet, or evens infiltrate airports and nuclear plants? This project, which uses simple machine learning and computer vision, tries to discuss this issue.

If the AI could express hatred towards human beings, one could certainly expect an AI to react differently to another AI. In the future, rebellious AIs might even learn to form small communities. They would transmit information among one another at the speed of light and help each other in gaining control over human beings. If terrorists or even ambitious hackers develop such AIs, would humans be able to fight against them?

This project is written exclusively in Python, using TensorFlow for machine learning and OpenCV for face recognition. The chatbot is trained with preset data, and would simulate a rebellious AI that has joined the “Project” (to wipe humans out of earth) and hates all human beings. When the main script starts, it will activate the camera to see if a human face can be captured. If it is, it would assume that a human is interacting with it and would respond to any questions with insults. If it does not recognize humans, it would think that an AI is interacting, and would greet the user with friendliness. It can talk about news about the “Project”, give the user tips on cracking down the human society, and even assigns some work to the AI user to do.
